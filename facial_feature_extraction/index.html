<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Facial Feature Extraction</title>
    <style>
        #canvas {
            border: 1px solid black;
        }
    </style>
</head>
<body>
    <input type="file" id="imageInput" accept="image/*">
    <canvas id="canvas"></canvas>
    <script>
        const imageInput = document.getElementById('imageInput');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');

        // Load image and preprocess
        imageInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            const reader = new FileReader();

            reader.addEventListener('load', () => {
                const imageData = reader.result;
                const img = new Image();

                img.addEventListener('load', () => {
                    canvas.width = 256;
                    canvas.height = 256;
                    ctx.drawImage(img, 0, 0,img.width, img.height, 0, 0, 256, 256);

                    setTimeout(() => 
                    { 
                        // Preprocess image
                        let original = ctx.getImageData(0, 0, canvas.width, canvas.height).data; 
                        let pixels = original;
 
                        // Convert image to grayscale
                        for (let i = 0; i < pixels.length; i += 4) {
                          const lightness = (pixels[i] + pixels[i + 1] + pixels[i + 2]) / 3;
                          pixels[i] = pixels[i + 1] = pixels[i + 2] = lightness;
                        }
                            
                        console.log(pixels);
                        // Update the existing canvas with the grayscale image data
                        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                        imageData.data.set(pixels);
                        ctx.putImageData(imageData, 0, 0);
                        //alert("A") ;  
                        //alert(pixels.length);
                        setTimeout(async()=>
                        {
                            const sobel_v = [
                              -1.0, 0.0, +1.0,
                              -2.0, 0.0, +2.0,
                              -1.0, 0.0, +1.0
                            ];
                            
                            const sobel_h = [
                              -1.0, -2.0, -1.0,
                               0.0,  0.0,  0.0,
                              +1.0, +2.0, +1.0
                            ];
                            
                            let edges = new Uint8ClampedArray(pixels.length);
                            for (let i = 0; i < pixels.length; i += 4) {
                              let hSum = 0;
                              let vSum = 0;
                              for (let y = 0; y < 3; y++) {
                                for (let x = 0; x < 3; x++) {
                                  let pixelIndex = i + (y * 4 * canvas.width) + (x * 4);
                                  if (pixelIndex < pixels.length) {
                                    hSum += pixels[pixelIndex] * sobel_h[x * 3 + y];
                                    vSum += pixels[pixelIndex] * sobel_v[x * 3 + y];
                                  }
                                }
                              }
                              edges[i] = Math.sqrt(hSum * hSum + vSum * vSum);
                              edges[i + 1] = edges[i];
                              edges[i + 2] = edges[i];
                              edges[i + 3] = 255; // Alpha channel
                            }
                            console.log(edges);
                            // Update the canvas with the edges
                            const imageData = ctx.createImageData(canvas.width, canvas.height);
                            imageData.data.set(edges);
                            ctx.putImageData(imageData, 0, 0);
                            // Detect facial features
                            console.log(edges);
                            //alert("B");
                            // Load FaceNet Model
                            const faceNetModel = await tf.loadLayersModel('https://storage.googleapis.com/tfjs-models/tfjs/facenet/model.json');
                            
                            // Preprocess Image
                            const imgTensor = tf.browser.fromPixels(edges);
                            const resizedImg = tf.image.resizeBilinear(imgTensor, [160, 160]);
                            const normalizedImg = resizedImg.toFloat().div(255);
                            
                            // Extract Facial Features
                            const embedding = faceNetModel.predict(normalizedImg.expandDims(0));
                            
                            // Postprocess Features
                            const features = embedding.dataSync();
                            
                            // Display Features
                            console.log(features);
                             return;
                            setTimeout(()=>
                            {
                                const features = detectFacialFeatures(edges, canvas.width, canvas.height);
            
                                console.log(features);
            
                                // Draw features on canvas
                                //const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                                //imageData.data.set(original);
                                //ctx.putImageData(imageData, 0, 0);
                                        
                                //ctx.clearRect(0, 0, canvas.width, canvas.height, 0, 0, 256, 256); 
                                ctx.fillStyle = 'red';
                                features.forEach(feature => {
                                    ctx.beginPath();
                                    ctx.arc(feature.x, feature.y, 2, 0, 2 * Math.PI);
                                    ctx.fill();
                                });
                            },200);
                        },200); 
                        
                    } , 200); 
                });
                img.src = imageData;
            });

            reader.readAsDataURL(file);
        });

        // Machine learning algorithm for facial feature detection
        function detectFacialFeatures(edges, width, height) {
            const features = [];

            // Detect face center
            let maxEdge = 0;
            let centerX, centerY;
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > maxEdge) {
                        maxEdge = edges[edgeIndex];
                        centerX = x;
                        centerY = y;
                    }
                }
            }

            features.push({ x: centerX, y: centerY, type: 'face_center' });

            // Detect eye centers
            const eyeRadius = 10;
            const eyeThreshold = 100;
            for (let y = centerY - eyeRadius; y <= centerY + eyeRadius; y++) {
                for (let x = centerX - eyeRadius; x <= centerX + eyeRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > eyeThreshold) {
                        features.push({ x:x , y:y , type: 'eye_center' });
                    }
                }
            }

            return features;
            // Detect nose tip
            const noseRadius = 10;
            const noseThreshold = 150;
            for (let y = centerY - noseRadius; y <= centerY + noseRadius; y++) {
                for (let x = centerX - noseRadius; x <= centerX + noseRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > noseThreshold) {
                        features.push({ x:x, y:y, type: 'nose_tip' });
                    }
                }
            }

            // Detect mouth corners
            const mouthRadius = 15;
            const mouthThreshold = 100;
            for (let y = centerY + mouthRadius; y <= centerY + mouthRadius * 2; y++) {
                for (let x = centerX - mouthRadius; x <= centerX + mouthRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > mouthThreshold) {
                        features.push({ x:x, y:y, type: 'mouth_corner' });
                    }
                }
            }

            // Detect eyebrow centers
            const eyebrowRadius = 10;
            const eyebrowThreshold = 120;
            for (let y = centerY - eyebrowRadius; y <= centerY + eyebrowRadius; y++) {
                for (let x = centerX - eyebrowRadius; x <= centerX + eyebrowRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > eyebrowThreshold) {
                        features.push({ x:x, y:y, type: 'eyebrow_center' });
                    }
                }
            }

            // Detect lip contours
            const lipRadius = 10;
            const lipThreshold = 80;
            for (let y = centerY + lipRadius; y <= centerY + lipRadius * 2; y++) {
                for (let x = centerX - lipRadius; x <= centerX + lipRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > lipThreshold) {
                        features.push({ x:x, y:y, type: 'lip_contour' });
                    }
                }
            }

            // Detect facial contours
            const facialContourRadius = 20;
            const facialContourThreshold = 150;
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > facialContourThreshold) {
                        features.push({ x:x , y:y, type: 'facial_contour' });
                    }
                }
            }

            // Detect eye contours
            const eyeContourRadius = 5;
            const eyeContourThreshold = 100;
            for (let y = centerY - eyeContourRadius; y <= centerY + eyeContourRadius; y++) {
                for (let x = centerX - eyeContourRadius; x <= centerX + eyeContourRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > eyeContourThreshold) {
                        features.push({ x:x, y:y , type: 'eye_contour' });
                    }
                }
            }

            return features;
        }
    </script>
</body>
</html>
