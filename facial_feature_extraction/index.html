<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Facial Feature Extraction</title>
    <style>
        #canvas {
            border: 1px solid black;
        }
    </style>
</head>
<body>
    <input type="file" id="imageInput" accept="image/*">
    <canvas id="canvas"></canvas>
    
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@2.0.0/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@0.0.1/dist/face_landmarks_detection.js"></script>
    
    <script>
        const imageInput = document.getElementById('imageInput');
        const canvas = document.getElementById('canvas');
        const ctx = canvas.getContext('2d');

        // Load image and preprocess
        imageInput.addEventListener('change', (e) => {
            const file = e.target.files[0];
            const reader = new FileReader();

            reader.addEventListener('load', () => {
                const imageData = reader.result;
                const img = new Image();

                img.addEventListener('load', () => {
                    canvas.width = 256;
                    canvas.height = 256;
                    ctx.drawImage(img, 0, 0,img.width, img.height, 0, 0, 256, 256);

                    setTimeout(() => 
                    { 
                        // Preprocess image
                        let original = ctx.getImageData(0, 0, canvas.width, canvas.height).data; 
                        let pixels = original;
 
                        // Convert image to grayscale
                        for (let i = 0; i < pixels.length; i += 4) {
                          const lightness = (pixels[i] + pixels[i + 1] + pixels[i + 2]) / 3;
                          pixels[i] = pixels[i + 1] = pixels[i + 2] = lightness;
                        }
                            
                        console.log(pixels);
                        // Update the existing canvas with the grayscale image data
                        const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                        imageData.data.set(pixels);
                        ctx.putImageData(imageData, 0, 0);
                        //alert("A") ;  
                        //alert(pixels.length);
                        setTimeout(()=>
                        {
                            const sobel_v = [
                              -1.0, 0.0, +1.0,
                              -2.0, 0.0, +2.0,
                              -1.0, 0.0, +1.0
                            ];
                            
                            const sobel_h = [
                              -1.0, -2.0, -1.0,
                               0.0,  0.0,  0.0,
                              +1.0, +2.0, +1.0
                            ];
                            
                            let edges = new Uint8ClampedArray(pixels.length);
                            for (let i = 0; i < pixels.length; i += 4) {
                              let hSum = 0;
                              let vSum = 0;
                              for (let y = 0; y < 3; y++) {
                                for (let x = 0; x < 3; x++) {
                                  let pixelIndex = i + (y * 4 * canvas.width) + (x * 4);
                                  if (pixelIndex < pixels.length) {
                                    hSum += pixels[pixelIndex] * sobel_h[x * 3 + y];
                                    vSum += pixels[pixelIndex] * sobel_v[x * 3 + y];
                                  }
                                }
                              }
                              edges[i] = Math.sqrt(hSum * hSum + vSum * vSum);
                              edges[i + 1] = edges[i];
                              edges[i + 2] = edges[i];
                              edges[i + 3] = 255; // Alpha channel
                            }
                            console.log(edges);
                            // Update the canvas with the edges
                            const imageData = ctx.createImageData(canvas.width, canvas.height);
                            imageData.data.set(edges);
                            ctx.putImageData(imageData, 0, 0);
                            // Detect facial features
                            console.log(edges);
                            //alert("B");
                            
                            setTimeout(()=>
                            {
                                const features = detectFacialFeatures(edges, canvas.width, canvas.height);
            
                                console.log(features);
            
                                // Draw features on canvas
                                //const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);
                                //imageData.data.set(original);
                                //ctx.putImageData(imageData, 0, 0);
                                        
                                //ctx.clearRect(0, 0, canvas.width, canvas.height, 0, 0, 256, 256); 
                                const colorMap = {
                                  eye_center: 'red',
                                  eyebrow_center : 'green',
                                  nose_tip : 'blue',
                                  mouth_corner: 'yellow',
                                  lip_contour : 'blue' ,
                                  facial_contour : 'orange' ,
                                  eye_contour : 'pink' 
                                };
                                
                                features.forEach(feature => {
                                    ctx.fillStyle = colorMap[feature.type] ? colorMap[feature.type] : 'purple';
                                    
                                    ctx.beginPath();
                                    ctx.arc(feature.x, feature.y, 2, 0, 2 * Math.PI);
                                    ctx.fill();
                                });
                            },200);
                        },200); 
                        
                    } , 200); 
                });
                img.src = imageData;
            });

            reader.readAsDataURL(file);
        });

        //
        function convertToGrayScale(original) {
            let pixels = original;
            // Convert image to grayscale
            for (let i = 0; i < pixels.length; i += 4) {
                const lightness = (pixels[i] + pixels[i + 1] + pixels[i + 2]) / 3;
                pixels[i] = pixels[i + 1] = pixels[i + 2] = lightness;
            }
            return pixels;
        }
        function applyGaussianBlur(pixels, width, height) {
            const blurredPixels = new Uint8Array(pixels.length);
            const kernel = [
                0.0625, 0.125, 0.0625,
                0.125, 0.25, 0.125,
                0.0625, 0.125, 0.0625
            ];
        
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    let sum = 0;
                    for (let ky = -1; ky <= 1; ky++) {
                        for (let kx = -1; kx <= 1; kx++) {
                            const yy = y + ky;
                            const xx = x + kx;
                            if (yy >= 0 && yy < height && xx >= 0 && xx < width) {
                                sum += pixels[(yy * width) + xx] * kernel[ky * 3 + kx];
                            }
                        }
                    }
                    blurredPixels[(y * width) + x] = sum;
                }
            }
        
            return blurredPixels;
        }
        
        function sobelEdgeDetection(blurredPixels, width, height) {
            const edges = new Uint8Array(blurredPixels.length);
            const sobelX = [
                -1, 0, 1,
                -2, 0, 2,
                -1, 0, 1
            ];
            const sobelY = [
                -1, -2, -1,
                0, 0, 0,
                1, 2, 1
            ];
        
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    let sumX = 0;
                    let sumY = 0;
                    for (let ky = -1; ky <= 1; ky++) {
                        for (let kx = -1; kx <= 1; kx++) {
                            const yy = y + ky;
                            const xx = x + kx;
                            if (yy >= 0 && yy < height && xx >= 0 && xx < width) {
                                sumX += blurredPixels[(yy * width) + xx] * sobelX[ky * 3 + kx];
                                sumY += blurredPixels[(yy * width) + xx] * sobelY[ky * 3 + kx];
                            }
                        }
                    }
                    edges[(y * width) + x] = Math.sqrt(sumX * sumX + sumY * sumY);
                }
            }
        
            return edges;
        }
        // Machine learning algorithm for facial feature detection
        function detectFacialFeatures(edges, width, height) {
            const features = [];

            // Detect face center
            let maxEdge = 0;
            let centerX, centerY;
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > maxEdge) {
                        maxEdge = edges[edgeIndex];
                        centerX = x;
                        centerY = y;
                    }
                }
            }

            features.push({ x: centerX, y: centerY, type: 'face_center' });

            // Detect eye centers
            const eyeRadius = 10;
            const eyeThreshold = 100;
            for (let y = centerY - eyeRadius; y <= centerY + eyeRadius; y++) {
                for (let x = centerX - eyeRadius; x <= centerX + eyeRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > eyeThreshold) {
                        features.push({ x:x , y:y , type: 'eye_center' });
                    }
                }
            }

            // Detect nose tip
            const noseRadius = 10;
            const noseThreshold = 150;
            for (let y = centerY - noseRadius; y <= centerY + noseRadius; y++) {
                for (let x = centerX - noseRadius; x <= centerX + noseRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > noseThreshold) {
                        features.push({ x:x, y:y, type: 'nose_tip' });
                    }
                }
            }

            // Detect mouth corners
            const mouthRadius = 15;
            const mouthThreshold = 100;
            for (let y = centerY + mouthRadius; y <= centerY + mouthRadius * 2; y++) {
                for (let x = centerX - mouthRadius; x <= centerX + mouthRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > mouthThreshold) {
                        features.push({ x:x, y:y, type: 'mouth_corner' });
                    }
                }
            }

            // Detect eyebrow centers
            const eyebrowRadius = 10;
            const eyebrowThreshold = 120;
            for (let y = centerY - eyebrowRadius; y <= centerY + eyebrowRadius; y++) {
                for (let x = centerX - eyebrowRadius; x <= centerX + eyebrowRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > eyebrowThreshold) {
                        features.push({ x:x, y:y, type: 'eyebrow_center' });
                    }
                }
            }

            // Detect lip contours
            const lipRadius = 10;
            const lipThreshold = 80;
            for (let y = centerY + lipRadius; y <= centerY + lipRadius * 2; y++) {
                for (let x = centerX - lipRadius; x <= centerX + lipRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > lipThreshold) {
                        features.push({ x:x, y:y, type: 'lip_contour' });
                    }
                }
            }

            // Detect facial contours
            const facialContourRadius = 20;
            const facialContourThreshold = 150;
            for (let y = 0; y < height; y++) {
                for (let x = 0; x < width; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > facialContourThreshold) {
                        features.push({ x:x , y:y, type: 'facial_contour' });
                    }
                }
            }

            // Detect eye contours
            const eyeContourRadius = 5;
            const eyeContourThreshold = 100;
            for (let y = centerY - eyeContourRadius; y <= centerY + eyeContourRadius; y++) {
                for (let x = centerX - eyeContourRadius; x <= centerX + eyeContourRadius; x++) {
                    const edgeIndex = y * width * 4 + x * 4;
                    if (edges[edgeIndex] > eyeContourThreshold) {
                        features.push({ x:x, y:y , type: 'eye_contour' });
                    }
                }
            }

            return features;
        }
    </script>
</body>
</html>
